{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29c1d07f",
   "metadata": {},
   "source": [
    "Etape préliminaire "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a8d857",
   "metadata": {},
   "source": [
    "Avant de commencer le projet, il faut installer les packages dont nous allons avoir besoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92bb1634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5bd851",
   "metadata": {},
   "source": [
    "Etape 1 : Importation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ca68be",
   "metadata": {},
   "source": [
    "Afin que cette étape se déroule bien, il faut récupérer la base DS_BPE_2024_data.csv préalablement importée sur S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3093f768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le dataframe df_df_legisl peut être traité comme un data frame classique avec pandas\n",
      "Le dataframe df_infrastruct peut être traité comme un data frame classique avec pandas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4467/358226819.py:29: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_infrastruct = pd.read_csv(\"s3://hantier/DS_BPE_2024_data.csv\", sep=';')  # le séparateur utilisé est un ;\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# ÉTAPE 1 : DONNÉES ÉLECTORALES\n",
    "# =========================\n",
    "\n",
    "url_legisl = \"https://www.data.gouv.fr/api/1/datasets/r/ab337c6f-e7e8-4981-843c-45052b71096b\"\n",
    "path_legisl = \"/home/onyxia/work/Projet-Python-S3/code/results_legisl.xlsx\"\n",
    "\n",
    "# Téléchargement du fichier Excel\n",
    "response = requests.get(url_legisl)\n",
    "response.raise_for_status()\n",
    "\n",
    "with open(path_legisl, \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "# Lecture du fichier Excel\n",
    "df_legisl = pd.read_excel(path_legisl, sheet_name=0)\n",
    "\n",
    "print(\"Le dataframe df_df_legisl peut être traité comme un data frame classique avec pandas\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# ÉTAPE 2 : DONNÉES INFRASTRUCTURES (S3 SSPCloud)\n",
    "# =========================\n",
    "\n",
    "# Chemin S3 du fichier\n",
    "path_infra_s3 = \"s3://hantier/DS_BPE_2024_data.csv\"\n",
    "\n",
    "# Lecture directe depuis S3\n",
    "df_infrastruct = pd.read_csv(\"s3://hantier/DS_BPE_2024_data.csv\", sep=';')  # le séparateur utilisé est un ;\n",
    "print(\"Le dataframe df_infrastruct peut être traité comme un data frame classique avec pandas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea41d704",
   "metadata": {},
   "source": [
    "Etape 2 : Préparation du dataframe que nous allons utiliser\n",
    "\n",
    "1) Préparation des données législatives\n",
    "\n",
    "Résultat recherché : notre but est d'obtenir une table avec des variables permettant d'identifier la commune ('Code département', 'Libellé département', 'Code commune', 'Libellé commune') et une variable correspondant au bord politique de la commune 'bord_pol'.\n",
    "\n",
    "Ici, la variable nuance candidat prend en valeur un code qui correspond au parti politique du candidat. Nous allons remplacer cette variable par une variable numérique qui attribuera un score allant de - 2 (extrême gauche) à 2 (extrême droite) ce qui nous permettra ensuite en faisant une moyenne pondérée des trois candidats les plus plébiscités afin, ensuite de placer les infrastructures sur un axes gauche-droite du bord politique de la commune\n",
    "\n",
    "Les variables nuance prennent les valeurs suivantes : DIV, DSV, DVC, DVD, DVG, ECO, ENS, EXD, EXG, HOR, LR, REG, REC, RN, SOC, UDI, UG, UXD, COM, UDI\n",
    "\n",
    "On crée un dataframe (bord_pol) qui permet de rapidement faire le changement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62b8e089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informations sur le dataframe df_legisl_1\n",
      "Index(['Code département', 'Libellé département', 'Code commune',\n",
      "       'Libellé commune', 'Nuance candidat 1', 'Nuance candidat 2',\n",
      "       'Nuance candidat 3', 'Nuance candidat 4', 'Nuance candidat 5',\n",
      "       'Nuance candidat 6',\n",
      "       ...\n",
      "       '% Voix/exprimés 195', '% Voix/exprimés 196', '% Voix/exprimés 197',\n",
      "       '% Voix/exprimés 198', '% Voix/exprimés 199', '% Voix/exprimés 200',\n",
      "       '% Voix/exprimés 201', '% Voix/exprimés 202', '% Voix/exprimés 203',\n",
      "       '% Voix/exprimés 204'],\n",
      "      dtype='object', length=412)\n",
      "14515584\n",
      "  Code département Libellé département Code commune          Libellé commune  \\\n",
      "0                1                 Ain         1001  L'Abergement-Clémenciat   \n",
      "1                1                 Ain         1002    L'Abergement-de-Varey   \n",
      "2                1                 Ain         1004        Ambérieu-en-Bugey   \n",
      "3                1                 Ain         1005      Ambérieux-en-Dombes   \n",
      "4                1                 Ain         1006                  Ambléon   \n",
      "\n",
      "  Nuance candidat 1 Nuance candidat 2 Nuance candidat 3 Nuance candidat 4  \\\n",
      "0                UG               DIV               DIV               EXG   \n",
      "1               ECO               EXG                LR                UG   \n",
      "2               ECO               EXG                LR                UG   \n",
      "3                UG               DIV               DIV               EXG   \n",
      "4               ENS                UG               DSV               EXG   \n",
      "\n",
      "  Nuance candidat 5 Nuance candidat 6  ... % Voix/exprimés 195  \\\n",
      "0               ENS                RN  ...                 NaN   \n",
      "1               DVD               ENS  ...                 NaN   \n",
      "2               DVD               ENS  ...                 NaN   \n",
      "3               ENS                RN  ...                 NaN   \n",
      "4                LR                RN  ...                 NaN   \n",
      "\n",
      "  % Voix/exprimés 196 % Voix/exprimés 197 % Voix/exprimés 198  \\\n",
      "0                 NaN                 NaN                 NaN   \n",
      "1                 NaN                 NaN                 NaN   \n",
      "2                 NaN                 NaN                 NaN   \n",
      "3                 NaN                 NaN                 NaN   \n",
      "4                 NaN                 NaN                 NaN   \n",
      "\n",
      "  % Voix/exprimés 199 % Voix/exprimés 200 % Voix/exprimés 201  \\\n",
      "0                 NaN                 NaN                 NaN   \n",
      "1                 NaN                 NaN                 NaN   \n",
      "2                 NaN                 NaN                 NaN   \n",
      "3                 NaN                 NaN                 NaN   \n",
      "4                 NaN                 NaN                 NaN   \n",
      "\n",
      "  % Voix/exprimés 202 % Voix/exprimés 203 % Voix/exprimés 204  \n",
      "0                 NaN                 NaN                 NaN  \n",
      "1                 NaN                 NaN                 NaN  \n",
      "2                 NaN                 NaN                 NaN  \n",
      "3                 NaN                 NaN                 NaN  \n",
      "4                 NaN                 NaN                 NaN  \n",
      "\n",
      "[5 rows x 412 columns]\n",
      "   code                               libelle       score\n",
      "0   DIV                                Divers   1000000.0\n",
      "1   DSV                  Divers souverainiste         1.0\n",
      "2   DVC                         Divers centre         0.0\n",
      "3   DVD                         Divers droite         2.0\n",
      "4   DVG                         Divers gauche        -2.0\n",
      "5   ECO                           Ecologistes        -2.0\n",
      "6   ENS                        Ensemble (EM!)         1.0\n",
      "7   EXD                                     3         NaN\n",
      "8   EXG                                    -3         NaN\n",
      "9   HOR                               Horizon         1.0\n",
      "10   LR                      Les Républicains         2.0\n",
      "11  REG                         Régionalistes  10000000.0\n",
      "12  REC                            Reconquête         3.0\n",
      "13   RN                Rassemblement National         3.0\n",
      "14  SOC                           Socialistes        -2.0\n",
      "15  UDI  Union des démocrates et indépendants         1.0\n",
      "16   UG                    Union de la gauche         2.0\n",
      "17  UXD             Union de l'extrême droite         3.0\n",
      "18  COM                           Communistes         3.0\n",
      "19  UDI  Union des démocrates et indépendants        -1.0\n"
     ]
    }
   ],
   "source": [
    "liste_var_can = [\"Nuance candidat \"+ str(i) for i in range (1,205)]\n",
    "liste_var_voix= [\"% Voix/exprimés \"+ str(i) for i in range (1,205)]\n",
    "liste_var = [\"Code département\", \"Libellé département\", \"Code commune\", \"Libellé commune\"] + liste_var_can + liste_var_voix\n",
    "df_legisl_1 = df_legisl[liste_var]\n",
    "print(\"Informations sur le dataframe df_legisl_1\")\n",
    "print(df_legisl_1.columns)\n",
    "print(df_legisl_1.size)\n",
    "print(df_legisl_1.head())\n",
    "\n",
    "bord_pol = [[\"DIV\", \"Divers\", 1000000], \n",
    "[\"DSV\", \"Divers souverainiste\", 1], \n",
    "[\"DVC\", \"Divers centre\", 0], \n",
    "[\"DVD\", \"Divers droite\", 2], \n",
    "[\"DVG\", \"Divers gauche\", -2], \n",
    "[\"ECO\", \"Ecologistes\", -2], \n",
    "[\"ENS\", \"Ensemble (EM!)\", 1], \n",
    "[\"EXD\", 3], \n",
    "[\"EXG\", -3], \n",
    "[\"HOR\", \"Horizon\", 1], \n",
    "[\"LR\", \"Les Républicains\", 2], \n",
    "[\"REG\", \"Régionalistes\", 10000000], \n",
    "[\"REC\", \"Reconquête\",  3], \n",
    "[\"RN\", \"Rassemblement National\", 3], \n",
    "[\"SOC\", \"Socialistes\", -2], \n",
    "[\"UDI\", \"Union des démocrates et indépendants\", 1], \n",
    "[\"UG\", \"Union de la gauche\", 2], \n",
    "[\"UXD\", \"Union de l'extrême droite\", 3], \n",
    "[\"COM\", \"Communistes\", 3], \n",
    "[\"UDI\", \"Union des démocrates et indépendants\", -1]]\n",
    "\n",
    "df_politique = pd.DataFrame(bord_pol, columns=[\"code\", \"libelle\", \"score\"])\n",
    "print (df_politique)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca12872",
   "metadata": {},
   "source": [
    "2) Préparation des données infrastructures\n",
    "Dans un second temps, nous devons préparer le dataframe des infrastructures. Nous allons le passer d'un format long à un format large, autrement dit, au lieu d'avoir une ligne par infrastructure, nous aurons une ligne par ville et une colonne par infrastructure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec59e27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informations sur le dataframe df_infrastruct\n",
      "Index(['GEO', 'GEO_OBJECT', 'FACILITY_DOM', 'FACILITY_SDOM', 'FACILITY_TYPE',\n",
      "       'BPE_MEASURE', 'TIME_PERIOD', 'OBS_VALUE'],\n",
      "      dtype='object')\n",
      "18403840\n",
      "     GEO GEO_OBJECT FACILITY_DOM FACILITY_SDOM FACILITY_TYPE BPE_MEASURE  \\\n",
      "0  29305     UU2020            D            D1          D115  FACILITIES   \n",
      "1  77205     UU2020            D            D2          D265  FACILITIES   \n",
      "2  31113     UU2020            D            D2          D249  FACILITIES   \n",
      "3  41501     UU2020            D            D1          D112  FACILITIES   \n",
      "4  46104     UU2020            D            D2          D266  FACILITIES   \n",
      "\n",
      "   TIME_PERIOD  OBS_VALUE  \n",
      "0         2024          1  \n",
      "1         2024          4  \n",
      "2         2024          1  \n",
      "3         2024          1  \n",
      "4         2024          1  \n"
     ]
    }
   ],
   "source": [
    "print(\"Informations sur le dataframe df_infrastruct\")\n",
    "print(df_infrastruct.columns)\n",
    "print(df_infrastruct.size)\n",
    "print(df_infrastruct.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "669ef313",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_infra_large = (\n",
    "    df_infrastruct\n",
    "    .query(\"TIME_PERIOD == 2024\")\n",
    "    .groupby([\"GEO\", \"FACILITY_TYPE\"], as_index=False)[\"OBS_VALUE\"]\n",
    "    .sum()\n",
    "    .pivot(index=\"GEO\", columns=\"FACILITY_TYPE\", values=\"OBS_VALUE\")\n",
    "    .fillna(0)\n",
    "    .reset_index()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ac641a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vérifications sur le dataframe df_infra_large\n",
      "Index(['GEO', 'A101', 'A104', 'A105', 'A108', 'A109', 'A120', 'A121', 'A122',\n",
      "       'A124',\n",
      "       ...\n",
      "       'F312', 'F313', 'F314', 'F315', 'G101', 'G102', 'G103', 'G104', 'G105',\n",
      "       '_T'],\n",
      "      dtype='object', name='FACILITY_TYPE', length=231)\n",
      "15345330\n",
      "FACILITY_TYPE GEO  A101  A104  A105  A108  A109  A120  A121  A122  A124  ...  \\\n",
      "0               1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
      "1               2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
      "2               3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
      "3               4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
      "4               6   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
      "\n",
      "FACILITY_TYPE  F312  F313  F314  F315  G101  G102  G103  G104  G105       _T  \n",
      "0               0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  56142.0  \n",
      "1               0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  31024.0  \n",
      "2               0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  22125.0  \n",
      "3               0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  98005.0  \n",
      "4               0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  17237.0  \n",
      "\n",
      "[5 rows x 231 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Vérifications sur le dataframe df_infra_large\")\n",
    "print(df_infra_large.columns)\n",
    "print(df_infra_large.size)\n",
    "print(df_infra_large.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04349c7f",
   "metadata": {},
   "source": [
    "Une fois que nous avons réalisé cette étape, nous allons pouvoir joindre des bases."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
