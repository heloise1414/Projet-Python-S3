{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29c1d07f",
   "metadata": {},
   "source": [
    "Etape préliminaire "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a8d857",
   "metadata": {},
   "source": [
    "Avant de commencer le projet, il faut installer les packages dont nous allons avoir besoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92bb1634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5bd851",
   "metadata": {},
   "source": [
    "Etape 1 : Importation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ca68be",
   "metadata": {},
   "source": [
    "Afin que cette étape se déroule bien, il faut récupérer la base DS_BPE_2024_data.csv préalablement importée sur S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3093f768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etape 1.1 : téléchargement des données électorales par API\n",
    "\n",
    "url = \"https://www.data.gouv.fr/api/1/datasets/r/ab337c6f-e7e8-4981-843c-45052b71096b\"\n",
    "\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:  # si tout va bien on obtient 200 -> le code continue\n",
    "    with open(\"results_legisl.csv\", \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "    print(\"Téléchargement results_legisl.csv réussi !\")\n",
    "else:\n",
    "    print(\"Erreur HTTP :\", response.status_code)\n",
    "\n",
    "# path = os.path.expanduser(\"~/work/results_legisl.csv\")\n",
    "# print(os.path.exists(path), os.path.getsize(path))\n",
    "# with open(path, \"rb\") as f:\n",
    "#     print(f.read(200))\n",
    "# Ce code a mis en évidence que results_legisl est en fait un zip\n",
    "\n",
    "path = \"/home/onyxia/work/results_legisl.csv\"  # en réalité .zip !\n",
    "\n",
    "with zipfile.ZipFile(path, \"r\") as z:\n",
    "    files = z.namelist()\n",
    "    print(\"Contenu du ZIP :\", files)   # permet de voir ce que contient le zip\n",
    "\n",
    "\n",
    "path = os.path.expanduser(\"~/work/results_legisl.csv\")  # car c'est un .xlsx (ligne précédente)\n",
    "\n",
    "# Renommer pour clarifier\n",
    "os.rename(path, path.replace(\".csv\", \".xlsx\"))\n",
    "path = path.replace(\".csv\", \".xlsx\")\n",
    "\n",
    "# On lit le fichier excel avec pandas\n",
    "df_legisl = pd.read_excel(path, sheet_name=0)  # sheet_name=0 pour la première feuille\n",
    "\n",
    "print(\"Le dataframe df_legisl peut désormais être traité comme un data frame classique avec pandas\")\n",
    "\n",
    "\"\"\"#  Etape 2 : téléchargement des données infrastructures par API\n",
    "\n",
    "# On a d'abord essayé en téléchargeant comme un csv mais cela ne fonctionnait pas\n",
    "\n",
    "url = \"https://api.insee.fr/melodi/data/DS_BPE\"\n",
    "\n",
    "response = requests.get(url)\n",
    "#if response.status_code == 200:\n",
    "#    data_json = response.json()\n",
    "    print(\"Téléchargement JSON infrastructures réussi\")\n",
    "\n",
    "    # Vérifier la clé 'observations'\n",
    "    observations = data_json['observations']\n",
    "    print(f\"Nombre d'observations : {len(observations)}\")\n",
    "\n",
    "    # Convertir en DataFrame\n",
    "    df_infra = pd.DataFrame(observations)\n",
    "\n",
    "    # Afficher les premières lignes\n",
    "    print(df_infra.head())\n",
    "\n",
    "    # Sauvegarder si besoin\n",
    "    df_infra.to_csv(\"infrastruct.csv\", index=False, sep=';')\n",
    "\n",
    "else:\n",
    "    print(\"Erreur HTTP :\", response.status_code)\"\"\"\n",
    "# Etape 2 : récupération des données sur les infrastructures\n",
    "\n",
    "df_infrastruct = pd.read_csv(\"DS_BPE_2024_data.csv\", sep=';')  # le séparateur utilisé est un ;\n",
    "print(\"Le dataframe df_infrastruct peut être traité comme un data frame classique avec pandas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea41d704",
   "metadata": {},
   "source": [
    "Etape 2 : Préparation du dataframe que nous allons utiliser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b8e089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparation et nettoyage des bases de données\n",
    "\n",
    "print(\"Informations sur le dataframe df_legisl\")\n",
    "print(df_legisl.columns)\n",
    "print(df_legisl.size)\n",
    "print(df_legisl.head())\n",
    "\n",
    "print(\"Informations sur le dataframe df_infrastruct\")\n",
    "print(df_infrastruct.columns)\n",
    "print(df_infrastruct.size)\n",
    "print(df_infrastruct.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
