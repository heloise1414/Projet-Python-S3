{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29c1d07f",
   "metadata": {},
   "source": [
    "## Influence de l'environnement culturel sur le vote RN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6448e70",
   "metadata": {},
   "source": [
    "# Contexte\n",
    "\n",
    "A DEVELOPPER "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea51d40",
   "metadata": {},
   "source": [
    "Etape préliminaire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a8d857",
   "metadata": {},
   "source": [
    "Avant de commencer le projet, il faut installer les packages dont nous allons avoir besoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92bb1634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5bd851",
   "metadata": {},
   "source": [
    "Etape 1 : Importation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ca68be",
   "metadata": {},
   "source": [
    "1) Importation de la base données électorales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02561380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le dataframe df_infrastruct peut être traité comme un data frame classique avec pandas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8962/4256203287.py:7: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_infrastruct = pd.read_csv(\"s3://hantier/DS_BPE_2024_data.csv\", sep=';')  # le séparateur utilisé est un ;\n"
     ]
    }
   ],
   "source": [
    "# DONNÉES INFRASTRUCTURES (S3 SSPCloud)\n",
    "\n",
    "# Chemin S3 du fichier\n",
    "path_infra_s3 = \"s3://hantier/DS_BPE_2024_data.csv\"\n",
    "\n",
    "# Lecture directe depuis S3\n",
    "df_infrastruct = pd.read_csv(\"s3://hantier/DS_BPE_2024_data.csv\", sep=';')  # le séparateur utilisé est un ;\n",
    "print(\"Le dataframe df_infrastruct peut être traité comme un data frame classique avec pandas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f2f74b",
   "metadata": {},
   "source": [
    "2) Importation de la base infrastructures\n",
    "\n",
    "\n",
    "Afin que cette étape se déroule bien, il faut récupérer la base DS_BPE_2024_data.csv préalablement importée sur S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3093f768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le dataframe df_extrait peut être traité comme un data frame classique avec pandas\n",
      "Informations sur le dataframe df_extrait qui est notre df initial\n",
      "Index(['Code du département', 'Libellé du département', 'Code de la commune',\n",
      "       'Libellé de la commune', 'Etat saisie', 'Inscrits', 'Abstentions',\n",
      "       '% Abs/Ins', 'Votants', '% Vot/Ins',\n",
      "       ...\n",
      "       'Unnamed: 93', 'Unnamed: 94', 'Unnamed: 95', 'Unnamed: 96',\n",
      "       'Unnamed: 97', 'Unnamed: 98', 'Unnamed: 99', 'Unnamed: 100',\n",
      "       'Unnamed: 101', 'Unnamed: 102'],\n",
      "      dtype='object', length=103)\n",
      "35245\n",
      "Informations sur le dataframe df_elect\n",
      "Index(['Code du département', 'Libellé du département', 'Code de la commune',\n",
      "       'Libellé de la commune', 'Inscrits', 'Abstentions', '% Abs/Ins',\n",
      "       'score_rn', 'score_lfi'],\n",
      "      dtype='object')\n",
      "35245\n",
      "  Code du département Libellé du département  Code de la commune  \\\n",
      "0                  01                    Ain                   1   \n",
      "1                  01                    Ain                   2   \n",
      "2                  01                    Ain                   4   \n",
      "3                  01                    Ain                   5   \n",
      "\n",
      "     Libellé de la commune  Inscrits  Abstentions  % Abs/Ins  score_rn  \\\n",
      "0  L'Abergement-Clémenciat       645          108      16.74     28.65   \n",
      "1    L'Abergement-de-Varey       213           38      17.84     13.45   \n",
      "2        Ambérieu-en-Bugey      8765         2078      23.71     25.12   \n",
      "3      Ambérieux-en-Dombes      1282          234      18.25     34.24   \n",
      "\n",
      "   score_lfi  \n",
      "0      12.69  \n",
      "1      23.98  \n",
      "2      24.48  \n",
      "3      13.33  \n"
     ]
    }
   ],
   "source": [
    "url_elect = \"https://www.data.gouv.fr/api/1/datasets/r/6d9b33e5-667d-4c3e-9a0b-5fdf5baac708\"\n",
    "path_elect = \"/home/onyxia/work/Projet-Python-S3/code/results_elect.xlsx\"\n",
    "\n",
    "# Téléchargement du fichier Excel\n",
    "response = requests.get(url_elect)\n",
    "response.raise_for_status()\n",
    "\n",
    "with open(path_elect, \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "# Lecture du fichier Excel\n",
    "df_extrait = pd.read_excel(path_elect, sheet_name=0)\n",
    "\n",
    "print(\"Le dataframe df_extrait peut être traité comme un data frame classique avec pandas\")\n",
    "\n",
    "print(\"Informations sur le dataframe df_extrait qui est notre df initial\")\n",
    "print(df_extrait.columns)\n",
    "print(len(df_extrait))\n",
    "\n",
    "\n",
    "# la colonne unamed 53 correspond au nombre de voix de JLF, la colonne unamed 67 correspond à celui de marine le pen\n",
    "liste_var = ['Code du département', \n",
    "    'Libellé du département', \n",
    "    'Code de la commune', \n",
    "    'Libellé de la commune',\n",
    "    'Inscrits', \n",
    "    'Abstentions',\n",
    "    '% Abs/Ins',\n",
    "    'Unnamed: 53', \n",
    "    'Unnamed: 67']\n",
    "df_extrait2 = df_extrait[liste_var]\n",
    "df_extrait3 = df_extrait2.rename(columns={'Unnamed: 53': 'score_rn'})\n",
    "df_elect = df_extrait3.rename(columns={'Unnamed: 67': 'score_lfi'})\n",
    "print(\"Informations sur le dataframe df_elect\")\n",
    "print(df_elect.columns)\n",
    "print(len(df_elect))\n",
    "print(df_elect.head(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da70f64",
   "metadata": {},
   "source": [
    "2.1) Statistiques descriptives\n",
    "\n",
    "Statistiques descriptives sur df_elect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66c009fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le score moyen par commune du RN était\n",
      "29.075128387005247\n",
      "28.85\n",
      "Le score moyen par commune de LFI était\n",
      "16.511555681656972\n",
      "15.57\n"
     ]
    }
   ],
   "source": [
    "print(\"Le score moyen par commune du RN était\")\n",
    "print(df_elect[\"score_rn\"].mean())\n",
    "print(df_elect[\"score_rn\"].median())\n",
    "print(\"Le score moyen par commune de LFI était\")\n",
    "print(df_elect[\"score_lfi\"].mean())\n",
    "print(df_elect[\"score_lfi\"].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca12872",
   "metadata": {},
   "source": [
    "2) Préparation des données infrastructures\n",
    "Dans un second temps, nous devons préparer le dataframe des infrastructures. Nous allons le passer d'un format long à un format large, autrement dit, au lieu d'avoir une ligne par infrastructure, nous aurons une ligne par ville et une colonne par infrastructure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec59e27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informations sur le dataframe df_infrastruct\n",
      "Index(['GEO', 'GEO_OBJECT', 'FACILITY_DOM', 'FACILITY_SDOM', 'FACILITY_TYPE',\n",
      "       'BPE_MEASURE', 'TIME_PERIOD', 'OBS_VALUE'],\n",
      "      dtype='object')\n",
      "18403840\n",
      "     GEO GEO_OBJECT FACILITY_DOM FACILITY_SDOM FACILITY_TYPE BPE_MEASURE  \\\n",
      "0  29305     UU2020            D            D1          D115  FACILITIES   \n",
      "1  77205     UU2020            D            D2          D265  FACILITIES   \n",
      "2  31113     UU2020            D            D2          D249  FACILITIES   \n",
      "3  41501     UU2020            D            D1          D112  FACILITIES   \n",
      "4  46104     UU2020            D            D2          D266  FACILITIES   \n",
      "\n",
      "   TIME_PERIOD  OBS_VALUE  \n",
      "0         2024          1  \n",
      "1         2024          4  \n",
      "2         2024          1  \n",
      "3         2024          1  \n",
      "4         2024          1  \n"
     ]
    }
   ],
   "source": [
    "print(\"Informations sur le dataframe df_infrastruct\")\n",
    "print(df_infrastruct.columns)\n",
    "print(df_infrastruct.size)\n",
    "print(df_infrastruct.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "669ef313",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_infra_large = (\n",
    "    df_infrastruct\n",
    "    .query(\"TIME_PERIOD == 2024\")\n",
    "    .groupby([\"GEO\", \"FACILITY_TYPE\"], as_index=False)[\"OBS_VALUE\"]\n",
    "    .sum()\n",
    "    .pivot(index=\"GEO\", columns=\"FACILITY_TYPE\", values=\"OBS_VALUE\")\n",
    "    .fillna(0)\n",
    "    .reset_index()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ac641a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vérifications sur le dataframe df_infra_large\n",
      "Index(['GEO', 'A101', 'A104', 'A105', 'A108', 'A109', 'A120', 'A121', 'A122',\n",
      "       'A124',\n",
      "       ...\n",
      "       'F312', 'F313', 'F314', 'F315', 'G101', 'G102', 'G103', 'G104', 'G105',\n",
      "       '_T'],\n",
      "      dtype='object', name='FACILITY_TYPE', length=231)\n",
      "15345330\n",
      "FACILITY_TYPE GEO  A101  A104  A105  A108  A109  A120  A121  A122  A124  ...  \\\n",
      "0               1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
      "1               2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
      "2               3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
      "3               4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
      "4               6   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
      "\n",
      "FACILITY_TYPE  F312  F313  F314  F315  G101  G102  G103  G104  G105       _T  \n",
      "0               0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  56142.0  \n",
      "1               0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  31024.0  \n",
      "2               0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  22125.0  \n",
      "3               0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  98005.0  \n",
      "4               0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  17237.0  \n",
      "\n",
      "[5 rows x 231 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Vérifications sur le dataframe df_infra_large\")\n",
    "print(df_infra_large.columns)\n",
    "print(df_infra_large.size)\n",
    "print(df_infra_large.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
